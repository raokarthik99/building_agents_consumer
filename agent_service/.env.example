HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# Shared model defaults. Use GOOGLE for Gemini (direct) or keep LITELLM for other providers.
DEFAULT_MODEL_PROVIDER=GOOGLE # Use GOOGLE if using Gemini. Use LiteLLM for any other model provider like OpenAI, Anthropic, Azure AI, Ollama, etc.
DEFAULT_MODEL=gemini-2.5-flash # IMPORTANT NOTE: For Gemini, pass the model name directly like 'gemini-2.5-pro' (find all the official model names here --> https://ai.google.dev/gemini-api/docs/models) instead of 'google/gemini-2.5-pro'. For LiteLLM, it follows what is expected by LiteLLM for the various different LLM providers. For example, here's what the doc says for Anthropic ('anthropic/claude-sonnet-4-5-20250929') --> https://docs.litellm.ai/docs/providers/anthropic

SUPABASE_URL=https://your-project.supabase.co
SUPABASE_API_KEY=your-supabase-service-role-key
SUPABASE_JWT_SECRET=your-supabase-jwt-secret
SUPABASE_JWT_AUDIENCE=authenticated
SUPABASE_JWT_ISSUER=https://your-project.supabase.co/auth/v1

# Tooling keys
COMPOSIO_API_KEY=your-composio-api-key

# Google ADK can call Gemini / Vertext AI directly. Retrieve the API key from Google AI Studio:
# https://google.github.io/adk-docs/agents/models/#google-ai-studio
GOOGLE_API_KEY=your-google-ai-studio-api-key
GOOGLE_GENAI_USE_VERTEXAI=false # If using Vertex AI, change the setup according to https://google.github.io/adk-docs/agents/models/#google-cloud-vertex-ai

# LiteLLM provider naming & API key guidance: https://docs.litellm.ai/docs/providers
ANTHROPIC_API_KEY=your-anthropic-api-key
